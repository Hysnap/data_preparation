{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Paul Golder - Capstone Project March 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Using Generative AI - Create a persona or several personas to represent clients and generate requirements for a dashboard.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write down which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* User Stories to be translated into acceptance criteria\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'h:\\\\VScode\\\\CapStoneProject_2025\\\\Requirements'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The file README.md does not exist in the current directory\n",
            "You are in the directory:  h:\\VScode\\CapStoneProject_2025\\Requirements\n",
            "Changing current directory to its parent directory\n",
            "You set a new current directory\n",
            "The file README.md exists in the current directory\n"
          ]
        }
      ],
      "source": [
        "# check current directory contains the file README.md\n",
        "if os.path.exists(\"README.md\"):\n",
        "    print(\"The file README.md exists in the current directory\")\n",
        "else:\n",
        "    print(\"The file README.md does not exist in the current directory\")\n",
        "    print(\"You are in the directory: \", current_dir)\n",
        "    print(\"Changing current directory to its parent directory\")\n",
        "    os.chdir(os.path.dirname(current_dir))\n",
        "    print(\"You set a new current directory\")\n",
        "    current_dir = os.getcwd()\n",
        "    if os.path.exists(\"README.md\"):\n",
        "        print(\"The file README.md exists in the current directory\")\n",
        "    else:\n",
        "        RuntimeError(\"The file README.md does not exist in the current directory, please check the current directory\")\n",
        "        print(\"Current Directory =\", current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# OpenAI API call and response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# set environment vaiable for openai api key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# set the openai api key\n",
        "\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code from https://www.analyticsvidhya.com/blog/2023/05/how-to-use-chatgpt-api-in-python/\n",
        "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "#     response = openai.ChatCompletion.create(\n",
        "#         model=model,\n",
        "#         messages=messages,\n",
        "#         temperature=0,\n",
        "#         )\n",
        "#     return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Initial code used a depreciated function so asked ChatGPT to provide an updated version\n",
        "from typing import Optional\n",
        "def get_completion(prompt: str,\n",
        "                   model: str = \"gpt-3.5-turbo\",\n",
        "                   temperature: float = 0.0,\n",
        "                   max_tokens: Optional[int] = None) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Generate a response from OpenAI's ChatCompletion API.\n",
        "\n",
        "    :param prompt: User input prompt.\n",
        "    :param model: Model to use (default: \"gpt-3.5-turbo\").\n",
        "    :param temperature: Controls randomness (default: 0.0).\n",
        "    :param max_tokens: Optional limit for response length.\n",
        "    :return: AI-generated response or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = openai.OpenAI()  # Initialize OpenAI client\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except openai.OpenAIError as e:\n",
        "        print(f\"OpenAI API error: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Failed to retrieve a response.\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt\n",
        "prompt = (\n",
        "    \"As a data-driven reporter investigating Fake News, \"\n",
        "    \"identify key requirements for a dashboard that helps track, analyze, and counter Fake News. \"\n",
        "    \"Consider data sources, key metrics, visualization needs, AI-driven analysis, and user roles.\"\n",
        ")\n",
        "\n",
        "# Call the function\n",
        "response = get_completion(prompt, max_tokens=150)\n",
        "\n",
        "# Print the response\n",
        "if response:\n",
        "    print(\"AI's Dashboard Recommendations for Fake News Monitoring:\\n\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"Failed to retrieve a response.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
